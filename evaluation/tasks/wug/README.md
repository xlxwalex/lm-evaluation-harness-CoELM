# Wug Test

### Paper

Title: `Counting the Bugs in ChatGPT's Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model`

Abstract: [https://arxiv.org/abs/2310.15113](https://arxiv.org/abs/2310.15113)

Large language models (LLMs) have recently reached an impressive level of linguistic capability, prompting comparisons with human language skills. However, there have been relatively few systematic inquiries into the linguistic capabilities of the latest generation of LLMs, and those studies that do exist (i) ignore the remarkable ability of humans to generalize, (ii) focus only on English, and (iii) investigate syntax or semantics and overlook other capabilities that lie at the heart of human language, like morphology. Here, we close these gaps by conducting the first rigorous analysis of the morphological capabilities of ChatGPT in four typologically varied languages (specifically, English, German, Tamil, and Turkish). We apply a version of Berko's (1958) wug test to ChatGPT, using novel, uncontaminated datasets for the four examined languages. We find that ChatGPT massively underperforms purpose-built systems, particularly in English. Overall, our results -- through the lens of morphology -- cast a new light on the linguistic capabilities of ChatGPT, suggesting that claims of human-like language skills are premature and misleading.

Homepage: [https://github.com/dmort27/chatgpts-wugs](https://github.com/dmort27/chatgpts-wugs)


### Citation

```
@inproceedings{weissweiler-etal-2023-counting,
    title = "Counting the Bugs in {C}hat{GPT}{'}s Wugs: A Multilingual Investigation into the Morphological Capabilities of a Large Language Model",
    author = "Weissweiler, Leonie  and
      Hofmann, Valentin  and
      Kantharuban, Anjali  and
      Cai, Anna  and
      Dutt, Ritam  and
      Hengle, Amey  and
      Kabra, Anubha  and
      Kulkarni, Atharva  and
      Vijayakumar, Abhishek  and
      Yu, Haofei  and
      Schuetze, Hinrich  and
      Oflazer, Kemal  and
      Mortensen, David",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.401",
    doi = "10.18653/v1/2023.emnlp-main.401",
    pages = "6508--6524",
    abstract = "Large language models (LLMs) have recently reached an impressive level of linguistic capability, prompting comparisons with human language skills. However, there have been relatively few systematic inquiries into the linguistic capabilities of the latest generation of LLMs, and those studies that do exist (i) ignore the remarkable ability of humans to generalize, (ii) focus only on English, and (iii) investigate syntax or semantics and overlook other capabilities that lie at the heart of human language, like morphology. Here, we close these gaps by conducting the first rigorous analysis of the morphological capabilities of ChatGPT in four typologically varied languages (specifically, English, German, Tamil, and Turkish). We apply a version of Berko{'}s (1958) wug test to ChatGPT, using novel, uncontaminated datasets for the four examined languages. We find that ChatGPT massively underperforms purpose-built systems, particularly in English. Overall, our results{---}through the lens of morphology{---}cast a new light on the linguistic capabilities of ChatGPT, suggesting that claims of human-like language skills are premature and misleading.",
}

```

### Groups and Tasks

#### Groups

* Not part of any group yet.

#### Tasks

* `wug`: `Determine whether the language model can predict the past tense of unseen words.`

